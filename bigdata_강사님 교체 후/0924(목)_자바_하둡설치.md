## 9/23(목)

#### 빅데이터 플랫폼 구축

--------

> 세팅

  **1. vmware 설치**  

  **2. vmware 가상머신 설치하기 - CentOS 7버전을 설치한다.**

  **3. 가상머신 복제하기**

​     **- 가상머신이 네 대 있다 가정하고 네 개의 가상머신을 만들어준다.**

​     **: ip확인**

  **4. 하둡 서버를 구축하기 위한 클러스터링 설정하기**

​     **- 방화벽해제**

​     **- 네트워크 설정**

​     **- DNS설정**

  **5. 각종 프로그램 설치**

​     **- SSH 프로토콜 설정**

​     **- hadoop을 테스트하기 위해서는 자바가 반드시 필요하므로**

​     **- java, hadoop을 설치하고 설정을 한 후 테스트한다.**

  **6. hadoop의 EchoSystem을 살펴보고 EchoSystem을 설치하여 테스트한다.** 

-------

> hadoop05 생성하기



##### **5. 각종 프로그램 설치 - 자바 설치** 

- 하둡이 자바 코드를 만들어진 API를 이용하여 작업해야 하므로 JDK를 설치하여야 한다.
- 자바는 다른 에코 시스템에서 모두 사용하므로 root 계정에서 설치



> jdk파일 리눅스로 이동

- sts 다운로드

- http://dist.springsource.com/release/STS/index.html

![image-20200924083842000](image\image-20200924083842000.png)

- 디폴트 서버 삭제 - runtime에서도 지우기 
- 압축 풀고 관리자 권한으로 실행 - Import

![image-20200924090000031](image\image-20200924090000031.png)

- 기존의 bigdatashop 카피

![image-20200924090104645](image\image-20200924090104645.png)



- window - preferences - web browser

![image-20200924090732779](image\image-20200924090732779.png)

- 서버 만들기 - bigdataShop이 들어가지는지 확인 





**5. 각종 프로그램 설치**

> JDK 다운



- https://www.oracle.com/index.html 에 접속

![image-20200924091600505](image\image-20200924091600505.png)



- products - java

![image-20200924091256781](image\image-20200924091256781.png)



- Download Java

![image-20200924091315506](image\image-20200924091315506.png)



- java Arch

![image-20200924091329681](image\image-20200924091329681.png)



- java SE8(8u211 and later)

![image-20200924091402341](image\image-20200924091402341.png)



- Linux x64 RPM Package 다운

![image-20200924091503030](image\image-20200924091503030.png)



> 리눅스 hadoop01과 연결 

- open prespective - remote System Exploer

![image-20200924092516437](image\image-20200924092516437.png)



- 오른쪽 버튼 -new - connection

![image-20200924092538036](image\image-20200924092538036.png)

- SSH Only

![image-20200924092608469](image\image-20200924092608469.png)



- hadoop01 ip주소 입력

![image-20200924092648431](image\image-20200924092648431.png)



- finish

![image-20200924092703636](image\image-20200924092703636.png)



- 루트 클릭 - root/bigdata 입력 

![image-20200924092746619](image\image-20200924092746619.png)



- yes

![image-20200924092828223](image\image-20200924092828223.png)



- 리눅스와 연결되어 이클립스로 파일 전송 가능 

![image-20200924092852608](image\image-20200924092852608.png)



> 리눅스로 파일 이동

- local files - Drives - c:\ (jdk.rpm 받은 파일로 이동) - 복사

![image-20200924093044877](image\image-20200924093044877.png)



- root - home - hadoop 에 copy

![image-20200924093218588](image\image-20200924093218588.png)



- hadoop01에서 jdk.rpm 들어온 것을 확인

![image-20200924093439874](image\image-20200924093439874.png)



- 압축 풀기 (rpm -Uvh 파일명)
  - -U :이전버전 있으면 업그레이드
  - v : 설치되는 과정을 보겠다
  - h: 설치과정을 #으로 보여짐
  - usr: 압축 푼 파일이 들어감

![image-20200924093713385](image\image-20200924093713385.png)



- usr - java 폴더 안에 압축 푼 파일 확인 가능

![image-20200924093855138](image\image-20200924093855138.png)



- 다른 hadoop에 copy(root 폴더에 copy)
  - (상대경로) scp ./jdk-8u251-linux-x62.rpm root@hadoop02:/root

![image-20200924100157420](image\image-20200924100157420.png)



- hadoop02로 들어가 압축풀기 (hadoop03, 04, 05 모두 실행)
  - 경로 안줘도 압추기 풀어짐 (접속에서 들어가면 root로 들어가므로 현재폴더에서 압축을 풀어 준다.)
  - 처음 압축파일을 root에 copy했으므로 

![image-20200924100409632](image\image-20200924100409632.png)



##### **5. 각종 프로그램 설치 - 하둡 설치**



> 하둡 다운로드 및 설치

- 1번 머신에서  apache.org 에 접속

![image-20200924100919741](image\image-20200924100919741.png)



- projects - project list

![image-20200924101115804](image\image-20200924101115804.png)



- hadoop

![image-20200924101431110](image\image-20200924101431110.png)



- download

![image-20200924101444984](image\image-20200924101444984.png)



- Apache release archive

![image-20200924101524052](image\image-20200924101524052.png)



- hadoop-1.2.1/

![image-20200924101613190](image\image-20200924101613190.png)



- hadoop-1.2.1.tar.gz 61M 다운

![image-20200924101705727](image\image-20200924101705727.png)

- 파일 저장 - 확인

![image-20200924101757030](image\image-20200924101757030.png)



- 다운로드 확인
  - 내폴더 - 다운로드 - hadoop.gz

![image-20200924102535278](image\image-20200924102535278.png)



> 한글 설정 

- 프로그램  - 시스템 도구 - 설정 

![image-20200924103205684](image\image-20200924103205684.png)



- 지역 및 언어 - +

![image-20200924103249571](image\image-20200924103249571.png)



- 한국어 클릭

![image-20200924103312045](image\image-20200924103312045.png)



- 한국어(Hangul) 추가

![image-20200924103329913](image\image-20200924103329913.png)



- 한국어(Hangul 설정)
  - Hangul , Shift+space 제거 선택 뒤 추가 버튼 클릭

![image-20200924103636985](image\image-20200924103636985.png)



- 확인
  - Alt_R이 나오지 않으면 한/영 키 버튼 누르면 됨

![image-20200924103444050](image\image-20200924103444050.png)



- 적용

![image-20200924103536450](image\image-20200924103536450.png)



- 하둡 계정으로 copy

![image-20200924103811079](image\image-20200924103811079.png)



- 하둡 계정에서 copy 확인

![image-20200924103919921](image\image-20200924103919921.png)



- tar 압축 풀기 
  - v : view 실행하는 과정을 화면에 보여줌
  - z : 다운로드 받을 때 파일 형식이 z zip이므로 
  - x: tar파일 압축풀 때 주는 옵션
  - f: 어떤 파일의 압축을 풀건지 파일 이름을 폴더 이름과 같이 작업할 수 있게 설정

![image-20200924105402577](C:\Users\whtpw\AppData\Roaming\Typora\typora-user-images\image-20200924105402577.png)

![image-20200924105438820](image\image-20200924105438820.png)



- 다른 머신에도 copy

![image-20200924105635781](image\image-20200924105635781.png)



- 다른 머신 tar파일 압축 풀기
  - 하둡 홈 디렉토리에 copy해서 경로 지정 안해도 된다.

![image-20200924105953453](image\image-20200924105953453.png)



> 하둡 설정 파일 등록 



- 하둡을 실행하기 위해 설정해야 하는 파일
  - **5개의 프로세스** : Name node, Secondary Namenode, Data node, Job tracker, Tast tracker

| 파일명          | 설명                                                         |
| --------------- | ------------------------------------------------------------ |
| hadoop-env.sh   | Shell이 돌 때 제일 먼저 호출되는 파일이다.<br />하둡 내에서 실행하는 명령어들이 사용하는 파일로 JDK 경로와 클래스 패스 등을 설정해야 한다. |
| masters         | 보조 네임노드를 실행할 서버를 설정                           |
| slaves          | 데이터 노드를 실행할 서버를 설정                             |
| core-site.xml   | HDFS와 맵리 듀스에서 사용할 환경설정 정보를 셋팅             |
| hdfs-site.xml   | HDFS에서 사용할 환경정보를 설정                              |
| Mapred-site.xml | 맵리듀스에서 사용할 환경설정 정보 세팅                       |



- hadoop01 머신에서 하둡 실행 중에 발생하는 데이터를 저장할 수 있는 임시 폴더를 생성

![image-20200924111839752](image\image-20200924111839752.png)



- 설정파일 수정

![image-20200924112048169](image\image-20200924112048169.png)



- hadoop-env.sh 파일 텍스트 편집기 open 

![image-20200924112102766](image\image-20200924112102766.png)



- 변경

  - 경로 변경

  ![image-20200924112344361](image\image-20200924112344361.png)

  - 파일 명을 copy하여 넣기

  ![image-20200924112237624](image\image-20200924112237624.png)



- masters 파일 설정

![image-20200924112557770](image\image-20200924112557770.png)

- secondary namenode
  - SNN의 역할은 백업 용도이다. 하지만, Master Namenode 즉 NN의 운영에 도움을 준다.

![image-20200924112710850](image\image-20200924112710850.png)



- slaves 파일 설정
  - datanode, tasktracker에 대한 설정

![image-20200924112728644](image\image-20200924112728644.png)

![image-20200924112813487](image\image-20200924112813487.png)



- core-site.xml 설정

  - 네임노드와 임시 폴더에 대한 내용을 정의한다.
  - core-site.xml 설정

  ![image-20200924113003070](image\image-20200924113003070.png)

  

  - 다른 프로그램으로 열기 

  ![image-20200924113300236](image\image-20200924113300236.png)

  

  - 모든 프로그램 보기

  ![image-20200924113317017](image\image-20200924113317017.png)

  

  - gedit 선택

  ![image-20200924113247710](image\image-20200924113247710.png)

  

  ![image-20200924113552377](image\image-20200924113552377.png)

  

- hdfs-site.xml 설정

![image-20200924113838651](image\image-20200924113838651.png)

![image-20200924130818479](image\image-20200924130818479.png)



- mapred-site.xml 설정

![image-20200924113852088](image\image-20200924113852088.png)

![image-20200924133019445](image\image-20200924133019445.png)



- 설정 파일 다른 머신에 복사하기(02, 03, 04)
  - conf 파일 밑의 모든 것

![image-20200924131556685](image\image-20200924131556685.png)



> 네임노드 초기화

- 네임노드를 초기화하는 과정에서 앞에서 변경한 모든 설정 파일을 읽고 여러 가지 객체를 생성하며 초기화하는 작업을 같이 진행한다.

![image-20200924132624279](image\image-20200924132624279.png)



> 하둡 실행하기

- **root계정에서 하게 되면 start하면서 사용한 모든 파일의 소유권한이 root로 변경되어 버려 네임노드가 실행되지 않는다.**
- 하둡 실행

![image-20200924133314971](image\image-20200924133314971.png)



- jsp : 실행중인 프로세스 확인 
- 하둡이 모두 실행된 후 하둡에 관련된 여러 가지 데몬이 실행되었는지 확인한다.
  - 이 중 한가지라도 실행되지 않았다면 하둡 프로그램을 stop시키고 다시 start하거나 log파일을 읽어 문제를 해결해야 한다.
  - /home/hadoop/hadoop-1.2.1/bin/stop-all.sh

![image-20200924133703223](image\image-20200924133703223.png)

< 로그 파일 >

![image-20200924134106031](image\image-20200924134106031.png)



- hadoop이 start 된 후 jps로 확인시 데몬이 모두 실행되어 있지 않은 경우

  - 오류 수정
  - 1번부터 4번 머신의 모든 tmp디렉토리를 삭제
  - 삭제가 완료된 후 tmp디렉토리를 다시 생성(mkdir)
  - conf 폴더의 모든 파일을 4개의 머신에 복사
  - 네임노드 초기화
  - hadoop start
  - jps로 데몬 확인

  

- 네임노드의 관리자 페이지
  - hadoop01:50070 
  - live nodes : 데이터 노드의 개수

![image-20200924141313757](image\image-20200924141313757.png)



> hdfs 명령어

- mkdir
- ls
- copyFromLocal
- cat



- input 디렉토리 생성

![image-20200924142218272](image\image-20200924142218272.png)



- input 디렉토리 생성 확인

![image-20200924142236758](image\image-20200924142236758.png)



- pwd : 현재 경로 확인

- bin의 hadoop 명령어 fs 
  - readme.txt 파일을 input 폴더에 복사

![image-20200924143058246](image\image-20200924143058246.png)



- 

![image-20200924143201588](image\image-20200924143201588.png)



- 분산환경 구축

![image-20200924143322363](image\image-20200924143322363.png)



> hadoop에서 mapreduce 실행하기

- .../bin/hadoop jar		jar 파일명	Driver파일	input파일	output파일

  ​																	|											|

  ​							main 메소드가 있는 자바 Application					  |

  ​																							mapreduce 처리 결과가 저장될 파일

  ​		=>input파일이나 output파일 모두 hdfs에 저장될 path명시 해줘야함



- mapreduce 실행

![image-20200924150333228](image\image-20200924150333228.png)



- 결과 확인

hadoop01:50070에 접속

![image-20200924150503152](image\image-20200924150503152.png)



![image-20200924150518265](image\image-20200924150518265.png)



![image-20200924150607589](image\image-20200924150607589.png)



![image-20200924150615782](image\image-20200924150615782.png)



- cat 명령어로 결과 확인

![image-20200924150753283](image\image-20200924150753283.png)



- hadoop01:50030

  - jobTracker의 관리자 페이지

  ![image-20200924150903837](image\image-20200924150903837.png)

  

  -  실행한 job의 상태 : word count

  ![image-20200924150958736](image\image-20200924150958736.png)



> wordcount test

- /input2 폴더를 hdfs에 생성
- LICENSE.txt를 저장하기
- mapreduce처리
- /output2에 저장하기

- input2 , output2 파일 삭제

![image-20200924155723696](image\image-20200924155723696.png)



- 종료 - suspend

![image-20200924155925079](image\image-20200924155925079.png)

